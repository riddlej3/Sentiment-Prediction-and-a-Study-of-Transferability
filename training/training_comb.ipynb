{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data/Load wordEmbeddings/Balance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.chdir('/home/ubuntu/Notebooks/capstone2/src')\n",
    "from training_data_cleaning import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "os.chdir('/home/ubuntu/Notebooks/capstone2/data')\n",
    "hotels = pd.read_pickle('hotels.pickle').drop_duplicates()\n",
    "os.chdir('/home/ubuntu/Notebooks/data/ta')\n",
    "ta_data = pd.read_pickle('ta_data2.pickle').replace(1.0,2.0).replace(0.0,2.0).sample(frac=.5,random_state=3)\n",
    "hotels = hotel_data_cleaning(hotels)\n",
    "ta_data = ta_data_cleaning(ta_data)\n",
    "X = pd.concat([ta_data,hotels],axis=0).reset_index().drop('index',axis=1)\n",
    "X,y = balance_df_comb(X,size=18264)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ubuntu/Notebooks/data')\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz',\n",
    "                                                 binary=True,\n",
    "                                                 limit=2000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and NN Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_valid,y_train,y_valid = train_test_split(X,y,test_size=.30,shuffle=True)\n",
    "\n",
    "maxlen = 150\n",
    "training_samples = x_train.shape[0]\n",
    "validation_samples = x_valid.shape[0]\n",
    "batch_size = 25\n",
    "embedding_dims = 300\n",
    "epochs = 2\n",
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(char_level=False,lower=True)\n",
    "token.fit_on_texts(X)\n",
    "# tokenize.texts_to_sequences(x_train.iloc[0])\n",
    "x_train_seq = pad_sequences(token.texts_to_sequences(x_train),maxlen=maxlen)\n",
    "x_valid_seq = pad_sequences(token.texts_to_sequences(x_valid),maxlen=maxlen)\n",
    "\n",
    "word_index = token.word_index\n",
    "max_words = len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((max_words,embedding_dims))\n",
    "for word,i in word_index.items():\n",
    "    if i < max_words:\n",
    "        try:\n",
    "            embedding_vector = word_vectors.get_vector(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "ohe = OneHotEncoder()\n",
    "y_train_new = ohe.fit_transform(y_train.values.reshape(-1,1))\n",
    "y_valid_new = ohe.fit_transform(y_valid.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM, Embedding\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(max_words,embedding_dim,input_length=maxlen))\n",
    "model3.add(Dropout(rate=.2))\n",
    "model3.add(LSTM(batch_size,return_sequences=False))\n",
    "model3.add(Dense(4,activation='softmax'))\n",
    "model3.layers[0].set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 51139 samples, validate on 21917 samples\n",
      "Epoch 1/2\n",
      "51139/51139 [==============================] - 523s 10ms/step - loss: 0.9606 - acc: 0.5671 - val_loss: 0.9106 - val_acc: 0.5972\n",
      "Epoch 2/2\n",
      "51139/51139 [==============================] - 516s 10ms/step - loss: 0.7747 - acc: 0.6686 - val_loss: 0.8756 - val_acc: 0.6035\n"
     ]
    }
   ],
   "source": [
    "model3.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',metrics=['acc'])\n",
    "history = model3.fit(x_train_seq,y_train_new.toarray(),epochs=epochs,\n",
    "                     batch_size=batch_size,\n",
    "                     validation_data=(x_valid_seq,\n",
    "                                      y_valid_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ubuntu/Notebooks/capstone/models')\n",
    "model3.save('first_model_combined.h5')\n",
    "os.getcwd()\n",
    "\n",
    "f = open(\"word_dict_combined.pickle\",\"wb\")\n",
    "pickle.dump(word_index,f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
