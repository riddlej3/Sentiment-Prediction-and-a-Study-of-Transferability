{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "os.chdir('/home/ubuntu/Notebooks/capstone2/src')\n",
    "from training_data_cleaning import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "os.chdir('/home/ubuntu/Notebooks/data/ta')\n",
    "ta_data = pd.read_pickle('ta_data2.pickle').replace(1.0,2.0).replace(0.0,2.0).sample(frac=.8,random_state=3)\n",
    "ta_data = ta_data_cleaning(ta_data)\n",
    "X = ta_data\n",
    "X,y = balance_df_ta(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ubuntu/Notebooks')\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz',\n",
    "                                                 binary=True,\n",
    "                                                 limit=3000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "X = ta_data['text']\n",
    "y = ta_data['ratings_overall']\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(X,y,test_size=.15)\n",
    "\n",
    "maxlen = 150\n",
    "training_samples = x_train.shape[0]\n",
    "validation_samples = x_valid.shape[0]\n",
    "batch_size = 25\n",
    "embedding_dims = 300\n",
    "epochs = 4\n",
    "embedding_dim = 300\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import nltk\n",
    "\n",
    "token = Tokenizer(char_level=False,lower=True)\n",
    "token.fit_on_texts(X)\n",
    "# tokenize.texts_to_sequences(x_train.iloc[0])\n",
    "x_train_seq = pad_sequences(token.texts_to_sequences(x_train),maxlen=maxlen)\n",
    "x_valid_seq = pad_sequences(token.texts_to_sequences(x_valid),maxlen=maxlen)\n",
    "\n",
    "word_index = token.word_index\n",
    "max_words = len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((max_words,embedding_dims))\n",
    "for word,i in word_index.items():\n",
    "    if i < max_words:\n",
    "        try:\n",
    "            embedding_vector = word_vectors.get_vector(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56582, 104758)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embedding_matrix.sum(axis=1) == 0).sum(),len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "y_train_new = ohe.fit_transform(y_train.values.reshape(-1,1))\n",
    "y_valid_new = ohe.fit_transform(y_valid.values.reshape(-1,1))\n",
    "\n",
    "# x_valid_seq2 = x_valid_seq.reshape(x_valid_seq.shape[0],x_valid_seq.shape[1],1)\n",
    "# x_train_seq2 = x_train_seq.reshape(x_train_seq.shape[0],x_train_seq.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7763, 150)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words,embedding_dim,input_length=maxlen))\n",
    "model.add(Dropout(rate=.2))\n",
    "model.add(LSTM(batch_size,return_sequences=True))\n",
    "model.add(Dropout(rate=.2))\n",
    "model.add(LSTM(batch_size,return_sequences=False))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "# model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 131182 samples, validate on 23150 samples\n",
      "Epoch 1/4\n",
      "131182/131182 [==============================] - 2298s 18ms/step - loss: 0.8731 - acc: 0.6050 - val_loss: 0.7675 - val_acc: 0.6542\n",
      "Epoch 2/4\n",
      "131182/131182 [==============================] - 2297s 18ms/step - loss: 0.7210 - acc: 0.6808 - val_loss: 0.7535 - val_acc: 0.6613\n",
      "Epoch 3/4\n",
      " 52125/131182 [==========>...................] - ETA: 21:50 - loss: 0.6268 - acc: 0.7298"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',metrics=['acc'])\n",
    "history = model.fit(x_train_seq,y_train_new.toarray(),epochs=epochs,\n",
    "                     batch_size=batch_size,\n",
    "                     validation_data=(x_valid_seq,\n",
    "                                      y_valid_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ubuntu/Notebooks/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('first_model_ta.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"word_dict_ta.pkl\",\"wb\")\n",
    "pickle.dump(word_index,f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
